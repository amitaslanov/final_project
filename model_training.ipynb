{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "aedf0586-a6c7-48c4-855d-8bcf96c9e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "url = \"https://github.com/amitaslanov/final_project/raw/main/output_all_students_Train_v10.xlsx\"\n",
    "\n",
    "# Read the Excel file from the URL\n",
    "xls = pd.ExcelFile(url)\n",
    "\n",
    "# Parse the first sheet of the Excel file\n",
    "df = xls.parse(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2126e2a-a653-4217-959c-312a41079e22",
   "metadata": {},
   "source": [
    "#### Part 2 - Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "794615ef-fdf0-4940-8025-15d9fb49603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"City\" column\n",
    "df.loc[:, 'City'] = df['City'].str.replace(' נהריה', 'נהריה')\n",
    "df.loc[:, 'City'] = df['City'].str.replace('נהריה', 'נהרייה')\n",
    "df.loc[:, 'City'] = df['City'].str.replace('שוהם', ' שוהם')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "598bfc08-aeab-4924-b338-9d9f995ec479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the \"price\" column\n",
    "df.loc[:, 'price'] = df['price'].astype(str).str.replace('[^\\d.]', '', regex=True)\n",
    "df.loc[:, 'price'] = pd.to_numeric(df['price'])\n",
    "\n",
    "# Drop rows with missing prices\n",
    "df.dropna(subset=['price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0a1bb73a-7af4-41f4-877f-ea2cef3a68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the \"room_number\" column\n",
    "df.loc[:, 'room_number'] = df['room_number'].astype(str).str.replace('[^\\d.]', '', regex=True)\n",
    "df.loc[:, 'room_number'] = pd.to_numeric(df['room_number'])\n",
    "\n",
    "rows_to_drop = df[df['room_number'] > 10].index\n",
    "\n",
    "# Drop the identified rows\n",
    "df = df.drop(rows_to_drop, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ec206c2c-efd3-4739-8f97-a0c1e98832e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Area\" column\n",
    "df.loc[:, 'Area'] = df['Area'].astype(str).str.replace('[^\\d.]', '', regex=True)\n",
    "df.loc[:, 'Area'] = pd.to_numeric(df['Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "1df69953-f618-4a94-b465-3d1686c6f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Street\" column\n",
    "df.loc[:, 'Street'] = df['Street'].str.replace(r\"[\\[\\]']\", '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f6c19f1b-d15d-4098-8fe3-f90f5584b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"number_in_street\" column\n",
    "df.loc[:, 'number_in_street'] = pd.to_numeric(df['number_in_street'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3138818f-b664-422f-8838-d84ecb4904a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"type\" column\n",
    "df.loc[:, 'type'] = df['type'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1349e17d-1a9f-40d2-81b5-6bbd474296be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"city_area\" column \n",
    "df.loc[:, 'city_area'] = df['city_area'].astype(str)\n",
    "df.loc[:, 'city_area'] = df['city_area'].apply(lambda x: '' if not re.match(r'^[\\u0590-\\u05FF\\s-]+$', x) else x)\n",
    "df.loc[:, 'city_area'] = df['city_area'].str.replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "097ab891-0adf-425a-b36c-4bfac93406f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amits\\AppData\\Local\\Temp\\ipykernel_22516\\2592325436.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.loc[:, 'floor_out_of'] = df['floor_out_of'].str.replace('\\s+', ' ')\n"
     ]
    }
   ],
   "source": [
    "# \"floor_out_of\" column\n",
    "df.loc[:, 'floor_out_of'] = df['floor_out_of'].str.replace('קומה', '')\n",
    "df.loc[:, 'floor_out_of'] = df['floor_out_of'].str.replace('קומת ', '')\n",
    "df.loc[:, 'floor_out_of'] = df['floor_out_of'].str.replace('מתוך', ' ')\n",
    "df.loc[:, 'floor_out_of'] = df['floor_out_of'].str.replace('מרתף', '-1')\n",
    "df.loc[:, 'floor_out_of'] = df['floor_out_of'].str.replace('קרקע', '0')\n",
    "df.loc[:, 'floor_out_of'] = df['floor_out_of'].str.replace('\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "c6d8627a-6a89-48b4-b244-7f4c21ef6cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"total_floors\" and \"floor_out_of\" columns\n",
    "df[['floor', 'total_floors']] = df['floor_out_of'].str.extract(r'(\\d+)\\D*(\\d*)')\n",
    "df['floor'] = df.apply(lambda row: row['total_floors'] if pd.isnull(row['floor']) else row['floor'], axis=1)\n",
    "df['total_floors'] = df.apply(lambda row: row['floor'] if pd.isnull(row['total_floors']) else row['total_floors'], axis=1)\n",
    "df = df.drop('floor_out_of', axis=1)\n",
    "\n",
    "# Define the list of types that should result in None for \"floor\" and \"total_floors\"\n",
    "types_to_ignore = [\"בית פרטי\", \"דו משפחתי\", \"מגרש\", \"נחלה\", \"קוטג'\", \"קוטג' טורי\"]\n",
    "\n",
    "# Update \"floor\" and \"total_floors\" to None for the specified types\n",
    "df.loc[df['type'].isin(types_to_ignore), ['floor', 'total_floors']] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "269a02c2-3410-4a41-8588-3c772960acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"has ___\" columns\n",
    "columns_to_convert = ['hasElevator ', 'hasParking ', 'hasBars ','hasStorage ','hasAirCondition ','hasBalcony ','hasMamad ','handicapFriendly ']\n",
    "for column in columns_to_convert:\n",
    "    df[column] = df[column].apply(lambda x: 0 if pd.isna(x) else (1 if x in [True, 'true'] else (0 if x in [False, 'false', 'אין', 'לא', 'no'] else (1 if any(word in str(x) for word in ['יש', 'כן', 'yes']) else 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "cd0b3621-9593-4e82-846e-a0c87719c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"entranceDate\" column\n",
    "df['entranceDate '] = df['entranceDate '].replace({\n",
    "    'גמיש': 'flexible',\n",
    "    'גמיש ': 'flexible',\n",
    "    'לא צויין': 'not_defined',\n",
    "    'מיידי': 'immediate'\n",
    "})\n",
    "\n",
    "\n",
    "df['days'] = \"\"\n",
    "\n",
    "date_format = \"%Y-%m-%d\"  \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    entrance_date = row['entranceDate ']\n",
    "    \n",
    "    if isinstance(entrance_date, datetime):\n",
    "        formatted_date = entrance_date.strftime(date_format)\n",
    "        \n",
    "        days = (entrance_date - datetime.now()).days\n",
    "        df.at[index, 'entranceDate '] = formatted_date\n",
    "        df.at[index, 'days'] = days\n",
    "        \n",
    "        if days < 180 or df.at[index, 'entranceDate '] == 'immediate':\n",
    "            df.at[index, 'entranceDate '] = \"less_than_6 months\"\n",
    "        elif 180 <= days <= 365:\n",
    "            df.at[index, 'entranceDate '] = \"months_6_12\"\n",
    "        else:\n",
    "            df.at[index, 'entranceDate '] = \"above_year\"\n",
    "            \n",
    "df = df.drop('days', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ffe66b33-f202-400a-b2ef-a4b322ce9fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"condition\" column\n",
    "df['condition '] = df['condition '].str.replace('FALSE', 'None')\n",
    "df['condition '] = df['condition '].str.replace('לא צויין', 'None')\n",
    "df['condition '].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "aa91c310-d823-40bd-96b7-50fb6cdb72dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"publishedDays\" column\n",
    "df['publishedDays '] = df['publishedDays '].apply(lambda x: re.sub('[^\\d]+', '', str(x)) if pd.notnull(x) else '')\n",
    "df['publishedDays '] = pd.to_numeric(df['publishedDays '], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "02212f84-a062-4d21-8e31-85c3fce467b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping rows that the price is less then 500k (probably a input error)\n",
    "df.drop(df[df['price'] < 500000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "1d7fd05f-1755-40dd-855a-6e47d743d8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in missing values\n",
    "df['floor'] = pd.to_numeric(df['floor'], errors='coerce')\n",
    "df['total_floors'] = pd.to_numeric(df['total_floors'], errors='coerce')\n",
    "df['floor'].fillna(0, inplace=True)\n",
    "df['total_floors'].fillna(0, inplace=True)\n",
    "\n",
    "df['num_of_images'].fillna(0, inplace=True)\n",
    "\n",
    "mean_value_room_number = df['room_number'].mean()\n",
    "df['room_number'].fillna(mean_value_room_number, inplace=True)\n",
    "\n",
    "mean_value_area = df['Area'].mean()\n",
    "df['Area'].fillna(mean_value_area, inplace=True)\n",
    "\n",
    "mean_value_number_in_street = df['number_in_street'].mean()\n",
    "df['number_in_street'].fillna(mean_value_number_in_street, inplace=True)\n",
    "\n",
    "mean_value_publishedDays = df['publishedDays '].mean()\n",
    "df['publishedDays '].fillna(mean_value_publishedDays, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b0463a1e-3451-4e09-abaa-28ce8d2807b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Street', 'city_area', 'description '], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6db1fe-93a9-482a-9e98-dad92aac4503",
   "metadata": {},
   "source": [
    "##### We decided to drop the street and city_area columns because there is alot of different streests and area in every city, and if we will do one-hot-encoding to these column we will get a huge data.\n",
    "##### From our knowledge these details has a very minor effect on the price.\n",
    "\n",
    "##### We decided to drop the details column because it is not categorial and the important details the written in it provided in the othe columns (rooms/area and more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d602fa4c-4394-4b91-90f9-cfe80c5e348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicate_rows = df.duplicated()\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Optional: Reset the index of the DataFrame\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd6c0ae-b599-45c5-b85b-3cc23809727e",
   "metadata": {},
   "source": [
    "#### one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b72f5d55-9380-4323-9ee6-4b733405d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to perform one-hot encoding on\n",
    "columns_to_encode = ['City', 'type', 'condition ', 'entranceDate ', 'furniture ']\n",
    "\n",
    "# Perform one-hot encoding\n",
    "encoded_df = pd.get_dummies(df, columns=columns_to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "1a54984a-f9c9-4aab-80ab-571552e0dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df.columns = encoded_df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f228534-75f3-4477-9a55-a700505c98a4",
   "metadata": {},
   "source": [
    "#### features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "6d1475c9-b547-4101-a0ea-489fb2f063e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "hasElevator\n",
      "hasBars\n",
      "hasStorage\n",
      "hasAirCondition\n",
      "hasBalcony\n",
      "handicapFriendly\n",
      "City_שוהם\n",
      "City_אילת\n",
      "City_ביתשאן\n",
      "City_בתים\n",
      "City_גבעתשמואל\n",
      "City_חולון\n",
      "City_ירושלים\n",
      "City_נהרייה\n",
      "City_נתניה\n",
      "City_צפת\n",
      "City_קריתביאליק\n",
      "City_רחובות\n",
      "City_תלאביב\n",
      "type_אחר\n",
      "type_ביתפרטי\n",
      "type_בניין\n",
      "type_דומשפחתי\n",
      "type_דופלקס\n",
      "type_דירה\n",
      "type_דירתגג\n",
      "type_דירתגן\n",
      "type_טריפלקס\n",
      "type_מיניפנטהאוז\n",
      "type_נחלה\n",
      "type_קוטגטורי\n",
      "condition_None\n",
      "condition_דורששיפוץ\n",
      "condition_חדש\n",
      "condition_ישן\n",
      "condition_משופץ\n",
      "condition_שמור\n",
      "furniture_אין\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Assuming features_selection_data is your feature matrix and 'price' is the target variable\n",
    "X = encoded_df.drop('price', axis=1)\n",
    "y = encoded_df['price']\n",
    "\n",
    "# Create the linear regression model (or choose a different model)\n",
    "model = LinearRegression()\n",
    "\n",
    "# Create the RFE object with automatic feature selection\n",
    "rfe = RFE(estimator=model, n_features_to_select=None)\n",
    "\n",
    "# Fit the RFE model to the data\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_indices = rfe.support_\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_features = X.columns[selected_indices]\n",
    "\n",
    "# Print the selected feature names\n",
    "print(\"Selected Features:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e2ce05-3a50-4190-b182-60d23220fb05",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### We noticed that the room_number and Area columns wasnt chosen and we know these features can highly effect the property price so we will add them.\n",
    "###### We also noticed there is only 1 options of furniture (out of 4) so we will drop it.\n",
    "###### So we will check the correlation between these two features and the price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "1244d00d-8cd0-4acc-bebc-6ed88aec595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = selected_features.tolist()\n",
    "selected_features.append('room_number')\n",
    "selected_features.append('Area')\n",
    "selected_features.remove('furniture_אין')\n",
    "selected_features = pd.Index(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "1c2b8103-77d1-4a56-a9a8-db98c5204fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3248272135008.5693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming selected_features contains the list of selected feature names\n",
    "X = encoded_df[selected_features]\n",
    "y = encoded_df['price']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the Elastic Net model\n",
    "model = ElasticNet(alpha=0.5, l1_ratio=0.5)  # Adjust alpha and l1_ratio as needed\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b02b5508-de91-420b-bf42-b22f7204b866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_model.pkl']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "import joblib\n",
    "\n",
    "# Assuming selected_features contains the list of selected feature names\n",
    "X = encoded_df[selected_features]\n",
    "y = encoded_df['price']\n",
    "\n",
    "# Create and fit the Elastic Net model\n",
    "model = ElasticNet(alpha=0.5, l1_ratio=0.5)  # Adjust alpha and l1_ratio as needed\n",
    "model.fit(X, y)\n",
    "\n",
    "# Save the trained model as a PKL file\n",
    "joblib.dump(model, 'trained_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb674c6f-9845-4ccb-89d7-e1e2ab2afe97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
